{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8277d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"..\")  # proje kök klasörüne erişim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import joblib\n",
    "from utils.model_train_functions import ModelTrainFunctions\n",
    "import catboost as cb\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import optuna\n",
    "import warnings\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seed_value = 277\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bbb3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.dirname(os.getcwd())  # Proje kök klasörünü al\n",
    "unseen_size = 744  # Gelecek 31 gün için saatlik tahmin\n",
    "config_path = BASE_DIR + \"\\\\data\\\\raw\\\\train_config.json\"\n",
    "\n",
    "with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "mtf = ModelTrainFunctions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69a76ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = BASE_DIR + \"\\\\data\\\\processed\\\\\"\n",
    "historical_data, forecast_data = mtf.get_data(data_path=train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e911325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = historical_data.iloc[:-unseen_size, :]\n",
    "unseen = historical_data.iloc[-unseen_size:, :]\n",
    "forecast = forecast_data.copy()\n",
    "cat_cols = train.select_dtypes(include=[\"category\", \"object\"]).columns.tolist()\n",
    "train.shape, unseen.shape, forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8049a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 336\n",
    "n_splits = 3\n",
    "splits_info = mtf.get_tscv_splits((train.index), n_splits=n_splits, test_size=val_size)\n",
    "mtf.plot_splits(splits_info, train[\"consumption\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04132a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtf.print_splits_info(splits_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181f4524",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_1 = time.time()\n",
    "model_performance = {}\n",
    "selected_cols = []\n",
    "\n",
    "es = 50\n",
    "verbose = 50\n",
    "\n",
    "data = train.copy()\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    model_performance[trial.number] = {}\n",
    "    loss_function = trial.suggest_categorical(\"loss_function\", [\"RMSE\"])\n",
    "\n",
    "    param = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 10, 10),\n",
    "        \"loss_function\": loss_function,\n",
    "        \"eval_metric\": trial.suggest_categorical(\"eval_metric\", [\"RMSE\"]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "        \"allow_writing_files\": False,\n",
    "    }\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    total_mape_train = 0\n",
    "    total_mape_val = 0\n",
    "    total_mape_unseen = 0\n",
    "\n",
    "    split_count = len(splits_info)\n",
    "\n",
    "    for split in splits_info:\n",
    "        split_name = split[\"name\"]\n",
    "        print(f\"\\n\\nTraining on Trial: {trial.number} , {split_name}\\n\")\n",
    "        train = data[split[\"train_period\"][0] : split[\"train_period\"][1]].drop(\n",
    "            columns=selected_cols\n",
    "        )\n",
    "        val = data[split[\"val_period\"][0] : split[\"val_period\"][1]].drop(\n",
    "            columns=selected_cols\n",
    "        )\n",
    "        X_train, y_train = train.drop(columns=[\"consumption\"]), train[\"consumption\"]\n",
    "        print(\"Train data shape:\", X_train.shape)\n",
    "        print(\"Target length:\", len(y_train))\n",
    "        print(\"Any NaN in target:\", y_train.isna().sum())\n",
    "        print(\"Unique values in target:\", y_train.unique())\n",
    "\n",
    "        X_val, y_val = val.drop(columns=[\"consumption\"]), val[\"consumption\"]\n",
    "        print(\n",
    "            f\"Training data shape: {X_train.shape}, Validation data shape: {X_val.shape}\"\n",
    "        )\n",
    "\n",
    "        cat_cols = X_train.select_dtypes(\n",
    "            include=[\"category\", \"object\"]\n",
    "        ).columns.tolist()\n",
    "        train_pool = Pool(X_train, label=y_train, cat_features=cat_cols)\n",
    "        val_pool = Pool(X_val, label=y_val, cat_features=cat_cols)\n",
    "\n",
    "        model = CatBoostRegressor(**param)\n",
    "        model.fit(\n",
    "            train_pool, eval_set=val_pool, early_stopping_rounds=es, verbose=verbose\n",
    "        )\n",
    "\n",
    "        train_result = model.predict(X_train)\n",
    "        val_result = model.predict(X_val)\n",
    "        unseen_predict = model.predict(unseen.drop(columns=\"consumption\"))\n",
    "\n",
    "        train_mape_df, train_mape = mtf.calculate_mape(y_train, train_result)\n",
    "        val_mape_df, val_mape = mtf.calculate_mape(y_val, val_result)\n",
    "        unseen_mape_df, unseen_mape = mtf.calculate_mape(\n",
    "            unseen[\"consumption\"], unseen_predict\n",
    "        )\n",
    "\n",
    "        total_mape_train += train_mape\n",
    "        total_mape_val += val_mape\n",
    "        total_mape_unseen += unseen_mape\n",
    "\n",
    "        print(\n",
    "            f\"Score Train - {split_name}: {train_mape},\\nScore Val - {split_name}: {val_mape},\\nScore Unseen - {split_name}: {unseen_mape}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Actual Mean: {np.mean(unseen['consumption']):.3f},\\nPredicted Mean: {np.mean(unseen_predict):.3f}\"\n",
    "        )\n",
    "        print(\"*\" * 50, \"\\n\")\n",
    "\n",
    "        # Model performansını kaydetme\n",
    "        model_performance[trial.number][split_name] = {\n",
    "            \"hyperparameters\": param,\n",
    "            \"model\": model,\n",
    "            \"train_mape\": train_mape,\n",
    "            \"val_mape\": val_mape,\n",
    "            \"unseen_mape\": unseen_mape,\n",
    "            \"evals_result\": model.get_evals_result(),\n",
    "            \"importance\": model.get_feature_importance(),\n",
    "            \"train_df\": train_mape_df,\n",
    "            \"val_df\": val_mape_df,\n",
    "            \"unseen_df\": unseen_mape_df,\n",
    "            \"train\": train,\n",
    "            \"val\": val,\n",
    "            \"unseen\": unseen,\n",
    "        }\n",
    "\n",
    "    val_mape_set = {}\n",
    "    for col in model_performance[trial.number].keys():\n",
    "        val_mape = mtf.calculate_mape(\n",
    "            model_performance[trial.number][col][\"val_df\"][\"Gerçek\"].values,\n",
    "            model_performance[trial.number][col][\"val_df\"][\"Tahmin\"].values,\n",
    "        )[1]\n",
    "        val_mape_set[col] = val_mape\n",
    "    val_mape_set = pd.DataFrame(\n",
    "        data=val_mape_set.items(), columns=[\"Split\", \"Val_MAPE\"]\n",
    "    )\n",
    "    val_mape_std = np.std(val_mape_set[\"Val_MAPE\"])\n",
    "    val_mape_mean = np.mean(val_mape_set[\"Val_MAPE\"])\n",
    "\n",
    "    base_average_mape = total_mape_val / split_count\n",
    "    print(\n",
    "        f\"Trial completed in {(time.time() - start_time) / 60:.2f} minutes with average Validation MAPE: %{val_mape_mean:.3f} and STD: %{val_mape_std:.3f}\"\n",
    "    )\n",
    "\n",
    "    return val_mape_mean\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"CatBoost TSS Optimization\",\n",
    "    sampler=optuna.samplers.TPESampler(multivariate=True, seed=seed_value),\n",
    ")\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=2,\n",
    "    show_progress_bar=True,\n",
    "    # n_jobs=-1\n",
    ")\n",
    "\n",
    "end_1 = time.time()\n",
    "print(f\"Trials completed in {(end_1 - start_1) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4668b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.trials_dataframe().sort_values(\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_performance = model_performance[study.best_trial.number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215ad45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in best_model_performance.keys():\n",
    "    print(f\"{split}\")\n",
    "    print(f\"Train MAPE: {best_model_performance[split]['train_mape']:.2f}\")\n",
    "    print(f\"Validation MAPE: {best_model_performance[split]['val_mape']:.2f}\")\n",
    "    print(f\"Unseen MAPE: {best_model_performance[split]['unseen_mape']:.2f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119a4f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mape_mean = np.mean(\n",
    "    [\n",
    "        best_model_performance[split][\"train_mape\"]\n",
    "        for split in best_model_performance.keys()\n",
    "    ]\n",
    ")\n",
    "train_mape_std = np.std(\n",
    "    [\n",
    "        best_model_performance[split][\"train_mape\"]\n",
    "        for split in best_model_performance.keys()\n",
    "    ]\n",
    ")\n",
    "val_mape_mean = np.mean(\n",
    "    [\n",
    "        best_model_performance[split][\"val_mape\"]\n",
    "        for split in best_model_performance.keys()\n",
    "    ]\n",
    ")\n",
    "val_mape_std = np.std(\n",
    "    [\n",
    "        best_model_performance[split][\"val_mape\"]\n",
    "        for split in best_model_performance.keys()\n",
    "    ]\n",
    ")\n",
    "unseen_mape_mean = np.mean(\n",
    "    [\n",
    "        best_model_performance[split][\"unseen_mape\"]\n",
    "        for split in best_model_performance.keys()\n",
    "    ]\n",
    ")\n",
    "unseen_mape_std = np.std(\n",
    "    [\n",
    "        best_model_performance[split][\"unseen_mape\"]\n",
    "        for split in best_model_performance.keys()\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Train MAPE: Ortalama {:.2f}, Standart Sapma {:.2f}\".format(\n",
    "        train_mape_mean, train_mape_std\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Train MAPE Dağılımı\",\n",
    "    [\n",
    "        float(best_model_performance[split][\"train_mape\"])\n",
    "        for split in best_model_performance\n",
    "    ],\n",
    ")\n",
    "print(\"*\" * 50)\n",
    "print(\n",
    "    \"Validation MAPE: Ortalama {:.2f}, Standart Sapma {:.2f}\".format(\n",
    "        val_mape_mean, val_mape_std\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Validation MAPE Dağılımı\",\n",
    "    [\n",
    "        float(best_model_performance[split][\"val_mape\"])\n",
    "        for split in best_model_performance\n",
    "    ],\n",
    ")\n",
    "print(\"*\" * 50)\n",
    "print(\n",
    "    \"Unseen MAPE: Ortalama {:.2f}, Standart Sapma {:.2f}\".format(\n",
    "        unseen_mape_mean, unseen_mape_std\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Unseen MAPE Dağılımı\",\n",
    "    [\n",
    "        float(best_model_performance[split][\"unseen_mape\"])\n",
    "        for split in best_model_performance\n",
    "    ],\n",
    ")\n",
    "print(\"*\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6106d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_forecast = forecast.drop(\"consumption\", axis=1)\n",
    "model_result = pd.DataFrame(index=X_forecast.index)\n",
    "X_forecast = X_forecast.drop(columns=selected_cols)\n",
    "X_forecast = cb.Pool(X_forecast, cat_features=cat_cols)\n",
    "\n",
    "learn_metric = best_model_performance[\"Split 1\"][\"hyperparameters\"][\"eval_metric\"]\n",
    "\n",
    "after_iter = 1000\n",
    "fig, axs = plt.subplots(\n",
    "    len(best_model_performance.keys()), 2, figsize=(15, 10), sharex=\"col\"\n",
    ")\n",
    "fig.suptitle(\"Model Performance Across Splits\", fontsize=16)\n",
    "split_names = [col for col in best_model_performance.keys() if \"Split\" in col]\n",
    "\n",
    "for i, split in enumerate(split_names):\n",
    "    modelx = best_model_performance[split][\"model\"]\n",
    "    history = best_model_performance[split][\"evals_result\"]\n",
    "\n",
    "    # 1. Forecast Plot\n",
    "    forecast_predictions = modelx.predict(X_forecast)\n",
    "    model_result[split] = forecast_predictions\n",
    "\n",
    "    date_range = pd.to_datetime(forecast.index)\n",
    "\n",
    "    axs[i, 0].plot(\n",
    "        date_range, forecast_predictions, label=\"Forecast\", color=\"tab:blue\", alpha=0.7\n",
    "    )\n",
    "    axs[i, 0].set_title(f\"{split} - Forecast\")\n",
    "    axs[i, 0].set_ylabel(\"Değer\")\n",
    "    axs[i, 0].legend()\n",
    "    axs[i, 0].xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d\"))\n",
    "    axs[i, 0].xaxis.set_major_locator(mdates.DayLocator(interval=5))\n",
    "\n",
    "    # 2. Model Loss Plot\n",
    "    axs[i, 1].plot(\n",
    "        history[\"learn\"][learn_metric][after_iter:],\n",
    "        label=\"Learning Loss\",\n",
    "        color=\"tab:orange\",\n",
    "    )\n",
    "    axs[i, 1].plot(\n",
    "        history[\"validation\"][learn_metric][after_iter:],\n",
    "        label=\"Validation Loss\",\n",
    "        color=\"tab:green\",\n",
    "    )\n",
    "    axs[i, 1].set_title(f\"{split} - Model Loss (After {after_iter} Iterations)\")\n",
    "    axs[i, 1].set_ylabel(\"Loss\")\n",
    "    axs[i, 1].legend()\n",
    "\n",
    "# Genel ayarlamalar\n",
    "for ax in axs[-1, :]:  # Son satırın x ekseninde tarih formatı ayarı\n",
    "    ax.set_xlabel(\"Zaman\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4101e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtf.all_splits_mape_analysis(best_model_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc76d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtf.all_splits_mape_analysis_v2(best_model_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = {}\n",
    "\n",
    "split_names = [col for col in best_model_performance.keys() if \"Split\" in col]\n",
    "for split in split_names:\n",
    "    split_model = best_model_performance[split][\"model\"]\n",
    "    split_predict = split_model.predict(\n",
    "        best_model_performance[split_names[-1]][\"unseen\"].drop(columns=\"consumption\")\n",
    "    )\n",
    "    predicts[split] = split_predict\n",
    "predicts = pd.DataFrame(predicts)\n",
    "\n",
    "predicts.index = best_model_performance[split_names[-1]][\"unseen_df\"].index\n",
    "predicts[\"Gerçek\"] = best_model_performance[split_names[-1]][\"unseen_df\"][\n",
    "    \"Gerçek\"\n",
    "].values\n",
    "\n",
    "mape_scores = {}\n",
    "for col in predicts.columns:\n",
    "    mape_scores[col] = mtf.calculate_mape(predicts[\"Gerçek\"], predicts[col])[1]\n",
    "all_mape_df = pd.DataFrame(mape_scores.items(), columns=[\"Model\", \"Unseen Mape\"]).iloc[\n",
    "    :-1, :\n",
    "]\n",
    "all_mape_df[\"Validation Mape\"] = [\n",
    "    best_model_performance[split][\"val_mape\"] for split in best_model_performance.keys()\n",
    "]\n",
    "\n",
    "all_mape_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da745786",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Çubuk genişliği ve konum ayarları\n",
    "bar_width = 0.35\n",
    "index = all_mape_df.index\n",
    "\n",
    "# Çubuk grafikleri çiz\n",
    "bars1 = ax.bar(\n",
    "    index - bar_width / 2,\n",
    "    all_mape_df[\"Validation Mape\"],\n",
    "    bar_width,\n",
    "    color=\"#3498db\",\n",
    "    label=\"Validation MAPE\",\n",
    ")\n",
    "bars2 = ax.bar(\n",
    "    index + bar_width / 2,\n",
    "    all_mape_df[\"Unseen Mape\"],\n",
    "    bar_width,\n",
    "    color=\"#2ecc71\",\n",
    "    label=\"Unseen MAPE\",\n",
    ")\n",
    "\n",
    "# Başlık ve etiketler\n",
    "ax.set_title(\"Model MAPE Değerleri\", pad=15, fontsize=14, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Model\", fontsize=12, labelpad=10)\n",
    "ax.set_ylabel(\"MAPE Değeri (%)\", fontsize=12, labelpad=10)\n",
    "\n",
    "# X ekseni etiketlerini düzenle\n",
    "ax.set_xticks(index)\n",
    "ax.set_xticklabels(all_mape_df[\"Model\"], fontsize=11)\n",
    "\n",
    "# Y eksenini çerçeveye sığdır\n",
    "ax.set_ylim(\n",
    "    0, max(all_mape_df[\"Validation Mape\"].max(), all_mape_df[\"Unseen Mape\"].max()) * 1.2\n",
    ")\n",
    "\n",
    "# Izgara çizgileri\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.7, axis=\"y\")\n",
    "\n",
    "# Çubukların üstüne değer yaz\n",
    "for bars, label in zip([bars1, bars2], [\"Validation Mape\", \"Unseen Mape\"]):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            height,\n",
    "            f\"{height:.2f}%\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=10,\n",
    "            color=\"black\",\n",
    "        )\n",
    "\n",
    "# Lejant\n",
    "ax.legend(loc=\"upper right\", fontsize=10, frameon=False)\n",
    "\n",
    "# Layout ayarları\n",
    "fig.tight_layout()\n",
    "\n",
    "# Grafiği göster\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7eb628",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in best_model_performance.keys():\n",
    "    r2 = r2_score(\n",
    "        best_model_performance[split][\"unseen_df\"][\"Gerçek\"],\n",
    "        best_model_performance[split][\"unseen_df\"][\"Tahmin\"],\n",
    "    )\n",
    "\n",
    "    # Veri ve değişken sayısı\n",
    "    n = len(best_model_performance[split][\"unseen_df\"])  # Veri noktalarının sayısı\n",
    "    p = best_model_performance[split][\"unseen_df\"].shape[\n",
    "        1\n",
    "    ]  # Bağımsız değişkenlerin sayısı\n",
    "\n",
    "    # Adjusted R² hesaplama\n",
    "    adjusted_r2 = 1 - ((1 - r2) * (n - 1)) / (n - p - 1)\n",
    "\n",
    "    print(f\"{split}          R²: {r2:.4f}\")\n",
    "    print(f\"{split} Adjusted R²: {adjusted_r2:.4f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea18e6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"T V U --M {:.2f}, {:.2f}, {:.2f} ---- T V U--S {:.2f}, {:.2f}, {:.2f}\".format(train_mape_mean,val_mape_mean,unseen_mape_mean,\n",
    "#                                                                                   train_mape_std,val_mape_std,unseen_mape_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3841bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ımp = best_model_performance[\"Split 3\"][\"model\"].get_feature_importance(\n",
    "    prettified=True,\n",
    "    type=\"LossFunctionChange\",\n",
    "    data=Pool(\n",
    "        historical_data.drop(columns=\"consumption\"),\n",
    "        historical_data[\"consumption\"],\n",
    "        cat_features=cat_cols,\n",
    "    ),\n",
    ")\n",
    "model_ımp.loc[model_ımp.Importances > 1][\"Feature Id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cf44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(\n",
    "    best_model_performance,\n",
    "    f\"C:/Users/pc/Desktop/ULUDAG-ENERJI-DAGITILAN/models/\"\n",
    "    + \"T V U --M {:.2f}, {:.2f}, {:.2f} ---- T V U--S {:.2f}, {:.2f}, {:.2f}\".format(\n",
    "        train_mape_mean,\n",
    "        val_mape_mean,\n",
    "        unseen_mape_mean,\n",
    "        train_mape_std,\n",
    "        val_mape_std,\n",
    "        unseen_mape_std,\n",
    "    )\n",
    "    + \".joblib\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c9092",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_model = best_model_performance[\"Split 3\"][\"model\"]\n",
    "exp_model.save_model(\n",
    "    \"C:/Users/pc/Desktop/ULUDAG-ENERJI-DAGITILAN/models/exp_model.cbm\", format=\"cbm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43945d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
